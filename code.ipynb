{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "reference_fields_df = pd.read_csv(\"reference_fileds.csv\")\n",
    "reference_securities_df = pd.read_csv(\"reference_securities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview: \n",
    "# - Pulls all the column names from the corp_pfd.dif file and saves them in a set of strings dif_columns\n",
    "\n",
    "#Read the dif file as a string\n",
    "with open(\"corp_pfd.dif\", \"r\") as file:    \n",
    "    full_dif_string = file.read() \n",
    "\n",
    "#Grab all column names between the START/END-OF-FIELDS\n",
    "dif_columns =  re.search(\"START-OF-FIELDS(.*)END-OF-FIELDS\", full_dif_string, re.DOTALL)\n",
    "dif_columns= dif_columns.group(1)\n",
    "\n",
    "#Split based on new line to seperate every column name\n",
    "dif_columns= dif_columns.split(\"\\n\")\n",
    "\n",
    "#Filter out all headers containing '#' and blank lines\n",
    "dif_columns = [column for column in dif_columns if '#' not in column and column.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview: \n",
    "# - Creates DataFrame \n",
    "\n",
    "#Find all the columns in dif_column_name that are also in reference_feilds\n",
    "ref_fields_set = set(reference_fields_df['field'])\n",
    "res = [col for col in dif_columns if col in ref_fields_set] \n",
    "\n",
    "#creates an empty data frame with the appropriate column headers\n",
    "DataFrame= pd.DataFrame(columns=res)\n",
    "\n",
    "#This loop adds all the data from reference_securities_csv to DataFrame in the approriate columns\n",
    "for column in reference_securities_df.columns:\n",
    "    DataFrame[column.upper()]= reference_securities_df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overview: \n",
    "# - Formats the input dif file into a dataframe\n",
    "\n",
    "#Grab all the data in the dif file between the START/END-OF-DATA\n",
    "data_dif_string =  re.search(\"START-OF-DATA(.*)END-OF-DATA\", full_dif_string, re.DOTALL)\n",
    "data_dif_string= data_dif_string.group(1)\n",
    "\n",
    "#remove all leading and trailing spaces/new lines to prevent blank items in the list after splitting\n",
    "data_dif_string= data_dif_string.strip() \n",
    "\n",
    "#split based on new line to seperate every row\n",
    "seperated_data= data_dif_string.split(\"\\n\")\n",
    "\n",
    "#iterate every row and split based on '|' delimiter, then add each list of row values to all_rows\n",
    "all_rows=[]\n",
    "for row in seperated_data:\n",
    "    sep_rows = row.split(\"|\")\n",
    "    all_rows.append(sep_rows[:len(sep_rows)-1])  #each row ends with '|' so spliting by '|' leaves a trailing ' ' \n",
    "\n",
    "input_data= pd.DataFrame(all_rows,columns=dif_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview:\n",
    "# - Creates new_securities.csv\n",
    "\n",
    "#find all ids in input dif file not in reference_securities.csv\n",
    "ref_securities_ids= set(reference_securities_df['id_bb_global'])\n",
    "input_ids = set(input_data[\"ID_BB_GLOBAL\"])\n",
    "new_ids= input_ids - ref_securities_ids\n",
    "\n",
    "new_securities_rows=[]\n",
    "\n",
    "#creates a list of rows to add to the new_securities_df \n",
    "for id in new_ids:\n",
    "    first_index = input_data.index[input_data['ID_BB_GLOBAL'] == id][0]\n",
    "    row=[]\n",
    "    for column in reference_securities_df.columns:\n",
    "        new_val= input_data.at[first_index, column.upper()]\n",
    "        row.append(new_val)\n",
    "    new_securities_rows.append(row)\n",
    "\n",
    "new_securities_df= pd.DataFrame(new_securities_rows,columns=reference_securities_df.columns)\n",
    "\n",
    "# new_securities_df.to_csv(\"/Users/dominiclaiosa/Downloads/Resume/Cantor Assignment/new_securities.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overview:\n",
    "# - Creates Security_data.csv\n",
    "\n",
    "security_data= pd.DataFrame(columns=res)\n",
    "\n",
    "for col in res:\n",
    "    security_data[col]=input_data[col]\n",
    "\n",
    "#unpivots the data so for every ID there is a seperate row for each feild it has that contains a value\n",
    "security_data_unpivoted = security_data.melt(\n",
    "    id_vars=['ID_BB_GLOBAL'],  \n",
    "    var_name=\"FIELD\",          \n",
    "    value_name=\"VALUE\"         \n",
    ")\n",
    "\n",
    "#Pulls the date and time from the dif file- 'TIMEFINISHED=Mon May  3 19:50:37 EDT 2021' \n",
    "match = re.search(r\"TIMEFINISHED=(.*)\", full_dif_string)\n",
    "match= match.group(1).strip()\n",
    "timefinished_cleaned = re.sub(r\"\\s[A-Z]{3}\\s\", \" \", match)  # Removes \" EDT \"\n",
    "tstamp = pd.to_datetime(timefinished_cleaned).tz_localize(\"America/New_York\")\n",
    "\n",
    "#assigns source and tstamp vals\n",
    "security_data_unpivoted['SOURCE'] = \"corp_pfd.dif\"\n",
    "security_data_unpivoted['TSTAMP'] = tstamp\n",
    "\n",
    "#removes all rows with blank entries from the unpivoted data frame\n",
    "security_data_unpivoted = security_data_unpivoted.dropna(subset=[\"VALUE\"])\n",
    "security_data_unpivoted = security_data_unpivoted[security_data_unpivoted[\"VALUE\"].str.strip() != \"\"]\n",
    "\n",
    "#sorts the rows so all the same ID rows appear next to eachother\n",
    "security_data_unpivoted = security_data_unpivoted.sort_values(by=['ID_BB_GLOBAL', 'FIELD']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "security_data_unpivoted.to_csv(\"/Users/dominiclaiosa/Downloads/Resume/Cantor Assignment/securities_data.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
